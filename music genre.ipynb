{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from flask import Flask, request, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(trainingSet , instance , k):\n",
    "    distances =[]\n",
    "    for x in range (len(trainingSet)):\n",
    "        dist = distance(trainingSet[x], instance, k )+ distance(instance, trainingSet[x], k)\n",
    "        distances.append((trainingSet[x][2], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    print(\"neighbors is \",neighbors)\n",
    "    return neighbors   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearestClass(neighbors):\n",
    "    classVote ={}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x]\n",
    "        if response in classVote:\n",
    "            classVote[response]+=1 \n",
    "        else:\n",
    "            classVote[response]=1 \n",
    "    sorter = sorted(classVote.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    print(\"sorter is \",sorter)\n",
    "    return sorter[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='euJhZdzTIm8pop9_skQQSAuXh4dmvLIFYuR1N2Mq5NTe',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us-south.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'music-donotdelete-pr-nklfx6cua62dyo'\n",
    "object_key = 'my1.dat'\n",
    "\n",
    "streaming_body_2 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "import os\n",
    "\n",
    "\n",
    "f=open(\"my1.dat\",'wb')\n",
    "i=0\n",
    "#Dataset creation : making a dat file were we get all the data about the audio files in a \".dat\" file. \n",
    "for folder in os.listdir(directory):\n",
    "#as we have 10 classes, we're starting the loop from 1 to 11\n",
    "#so that we run the loop for total of 10 times, with each folder change (genre change), i (label) changes. \n",
    "    i += 1\n",
    "    if i==11 :\n",
    "        break\n",
    "    for file in os.listdir(directory+folder):\n",
    "#To read an Wav audio File in Python\n",
    "        (rate,sig) = wav.read(directory+folder+\"/\"+file)\n",
    "#MFCC is the feature we will use for our analysis,\n",
    "#because it provides data about the overall shape of the audio frequencies.\n",
    "        mfcc_feat = mfcc (sig, rate,winlen=0.020, appendEnergy = False)\n",
    "        covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "        mean_matrix = mfcc_feat.mean (0)\n",
    "#making a feature typle that contains the mean matrix from mfcc as well as covariance,\n",
    "#and last variable in the feature tuple is the label (where numbers correspond to particular genre) \n",
    "        feature = (mean_matrix, covariance, i)\n",
    "#This the the created dataset, which takes the input from specified path\n",
    "#it then stores the feature as a .dat file which can be used later without having to train all the files over it. \n",
    "        pickle.dump(feature, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the created dataset into a python readable object (list) dataset = []\n",
    "dataset=[]\n",
    "def loadDataset (filename):\n",
    "    with open(\"F:/notebook/jeemol/project/Flask/my1.dat\", 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                dataset.append(pickle.load(f))\n",
    "            except EOFError: \n",
    "                f.close() \n",
    "                break\n",
    "loadDataset(\"F:/notebook/jeemol/project/Flask/my1.dat\")\n",
    "#we have to convert the dataset from a list to np array. \n",
    "dataset = np.array(dataset)\n",
    "#type(dataset) ##uncomment this line to check the type of (dataset),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test split on the dataset:\n",
    "#as the dataset contains features for all the audio files, #we have to split that manually into train and test data \n",
    "from sklearn.model_selection import train_test_split \n",
    "x_train,x_test = train_test_split(dataset, test_size=0.15)\n",
    "#Make prediction using KNN and get the accuracy on test data: \n",
    "leng = len(x_test)\n",
    "predictions = []\n",
    "for x in range (leng):\n",
    "    predictions.append(nearestClass (getNeighbors (x_train,x_test[x], 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm-watson-machine-learning in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.0.283)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (2022.12.7)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (4.11.3)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (1.26.11)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (0.3.3)\n",
      "Requirement already satisfied: pandas<1.5.0,>=0.24.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (1.4.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (2.28.1)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (0.8.10)\n",
      "Requirement already satisfied: ibm-cos-sdk==2.12.* in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (2.12.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (21.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.10.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk==2.12.*->ibm-watson-machine-learning) (0.10.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk==2.12.*->ibm-watson-machine-learning) (2.12.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk==2.12.*->ibm-watson-machine-learning) (2.12.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk-core==2.12.0->ibm-cos-sdk==2.12.*->ibm-watson-machine-learning) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas<1.5.0,>=0.24.2->ibm-watson-machine-learning) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas<1.5.0,>=0.24.2->ibm-watson-machine-learning) (1.23.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->ibm-watson-machine-learning) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->ibm-watson-machine-learning) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from importlib-metadata->ibm-watson-machine-learning) (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from lomond->ibm-watson-machine-learning) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging->ibm-watson-machine-learning) (3.0.9)\n",
      "tar: parkinson.pkl: Cannot stat: No such file or directory\n",
      "tar: Exiting with failure status due to previous errors\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ibm-watson-machine-learning\n",
    "!tar -zcvf music.tgz parkinson.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentials={\"url\":\"https://us-south.ml.cloud.ibm.com\", \n",
    "                 \"apikey\": \"TqjVLPC1pWR6M1FhYVyZBxZ-dc5w4GVCdK_d3i8OelAQ\"\n",
    "                }\n",
    "client=APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide_from_space_name(client,space_name):\n",
    "    space=client.spaces.get_details()\n",
    "    return(next(item for item in space['resources']if item['entity'][\"name\"]==space_name)['metadata']['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space UID =5eced59d-f9a1-454d-8789-1e71623e092e\n"
     ]
    }
   ],
   "source": [
    "space_uid=guide_from_space_name(client,'music')\n",
    "print(\"Space UID =\" + space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------------------------------  ----  ------------------  -------------------------------\n",
      "NAME                           ID                                    TYPE  STATE               REPLACEMENT\n",
      "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base  unsupported         runtime-22.1-py3.9\n",
      "kernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base  not_provided\n",
      "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base  not_provided\n",
      "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base  unsupported         runtime-22.1-py3.9\n",
      "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base  unsupported\n",
      "pytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base  supported\n",
      "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base  unsupported         runtime-22.1-py3.9\n",
      "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base  not_provided\n",
      "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base  unsupported         tensorflow_rt22.1-py3.9-horovod\n",
      "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base  unsupported\n",
      "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base  unsupported\n",
      "autoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base  supported\n",
      "runtime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base  supported\n",
      "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base  unsupported         runtime-22.1-py3.9\n",
      "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base  deprecated\n",
      "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base  unsupported         runtime-22.1-py3.9\n",
      "kernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base  not_provided\n",
      "pytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base  supported\n",
      "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base  unsupported         runtime-22.1-py3.9\n",
      "spark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base  unsupported         spark-mllib_3.3\n",
      "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base  unsupported         tensorflow_rt22.1-py3.9-horovod\n",
      "runtime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base  supported\n",
      "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base  not_provided\n",
      "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base  unsupported         autoai-ts_rt22.1-py3.9\n",
      "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base  unsupported         runtime-22.1-py3.9\n",
      "kernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base  not_provided\n",
      "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base  unsupported         runtime-22.1-py3.9\n",
      "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base  create-unsupported  spark-mllib_3.3\n",
      "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base  unsupported\n",
      "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base  unsupported         spark-mllib_3.3\n",
      "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base  unsupported         spark-mllib_3.3\n",
      "autoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base  supported\n",
      "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base  unsupported         runtime-22.1-py3.9\n",
      "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base  unsupported\n",
      "pytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base  supported\n",
      "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base  not_provided\n",
      "autoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base  supported\n",
      "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base  unsupported         autoai-obm_3.2\n",
      "pmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base  supported\n",
      "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base  unsupported         spark-mllib_3.3\n",
      "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base  unsupported         runtime-22.1-py3.9\n",
      "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base  unsupported         runtime-22.1-py3.9\n",
      "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base  unsupported         autoai-ts_rt22.1-py3.9\n",
      "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base  unsupported         spark-mllib_3.3\n",
      "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base  unsupported         spark-mllib_3.3\n",
      "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base  unsupported         autoai-obm_3.2\n",
      "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base  supported\n",
      "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base  not_provided\n",
      "runtime-22.2-py3.10-xc         5e8cddff-db4a-5a6a-b8aa-2d4af9864dab  base  supported\n",
      "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base  unsupported         autoai-kb_rt22.1-py3.9\n",
      "-----------------------------  ------------------------------------  ----  ------------------  -------------------------------\n",
      "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"
     ]
    }
   ],
   "source": [
    "client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12b83a17-24d8-5082-900f-0ab31fbfd3cb'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_spec_uid=client.software_specifications.get_uid_by_name(\"runtime-22.1-py3.9\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details=client.repository.store_model(model='music.tgz',meta_props={client.repository.ModelMetaNames.NAME:\"parkinson_model\",client.repository.ModelMetaNames.TYPE:\"scikit-learn_1.0\",client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid})\n",
    "model_id=client.repository.get_model_id(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'858ef1f1-a8fb-4c67-8af4-b61cfdb1b8d1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
